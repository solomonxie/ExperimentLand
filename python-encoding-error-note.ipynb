{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关于解决Python乱码问题的终极解决方案\n",
    "\n",
    "> 这里打算讨论各种常用方法\n",
    "\n",
    "简单来说，只要记住，在Python2里字符串只有两大阵营：\n",
    "\n",
    "## `unicode`和`bytes`\n",
    "\n",
    "如果`type(字符串)`显示结果是`str`，那么就是指的`bytes`二进制码。\n",
    "而其它各种我们所说的`utf-8`，`gb2312`等等也都是Unicode的不同实现方式。\n",
    "这里不要去考虑那么复杂，只要先记住这两大阵营就行。\n",
    "\n",
    "## `encoding`和`decoding`\n",
    "\n",
    "绝对要记住的：\n",
    "从`unicode`转换到`bytes`，这个叫`encoding`，编码。\n",
    "从`bytes`转换到`unicode`，这个叫`decoding`，解码。\n",
    "\n",
    "来回记住这个问题，才能进入下一步！\n",
    "\n",
    "然后来看个案例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'你好'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4f60\\u597d'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'你好'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u'你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b'你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(u'你好')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 通过上面两种格式的对比我们看到，str和unicode的各种区别。\n",
    "\n",
    "那么，既然变量里面会出现两种不同的格式，如果我们把两种格式的字符串连在一起操作会发生什么呢？\n",
    "如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni = u'你好'\n",
    "type(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byt = b'你好'\n",
    "type(byt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-b7e7514f02ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muni\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbyt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "uni + byt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 看！著名的`UnicodeDecodeError: 'ascii' codec can't decode byte`编码错误就这样出现了！\n",
    "\n",
    "以上是我们用`显性`字符串来比较两种格式字符串的区别。\n",
    "\n",
    "但是，我们经常性处理python编码问题，都不是在这种`显性`的字符串上出现的，不是从网上爬取的就是从本地文件读取的，意思就是文件内容庞大，编码格式很难猜到是什么。\n",
    "所以这里我们将问题再拆分为两部分讨论：本地文件和网络资源。\n",
    "\n",
    "## 本地文件编码测试\n",
    "首先在本地建立一个有中文的以`utf-8`格式保存的文本文件（实际上无论.txt还是.md等都无所谓，内容是一样的）。\n",
    "内容只有'你好'。\n",
    "\n",
    "### 然后我们来读取一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test.txt', 'r') as f:\n",
    "    ss = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 上面看到，从文件读取出来的，就是bytes二进制格式。\n",
    "那么如果要把bytes转化为unicode，就要解码，也就是decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4f60\\u597d'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这种时候实际上是最迷糊也最容易造成之后错误的，就是分不清该编码还是该解码。\n",
    "\n",
    "> 所以上面提到，必须要记住这两个区别。\n",
    "那么如果现在我搞反了怎么办？就会再次出现下面错误："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-9a2ff796dd55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "ss.encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 话说回来，我们该怎么统一他们呢？\n",
    "> 为了避免两种格式的字符串在一起乱搞，统一他们是必须的。但是以哪一种为统一的呢，unicode还是bytes?\n",
    "\n",
    "#### 下面我们来看看做常用的环境下字符串都是什么格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文中声明的变量\n",
    "type('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取本地文件\n",
    "ff = open('test.txt', 'r')\n",
    "type(ff.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'unicode'>\n",
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "# 获取网路资源\n",
    "import requests\n",
    "r = requests.get('http://pycoders-weekly-chinese.readthedocs.io/en/latest/issue5/unipain.html')\n",
    "print type(r.text)\n",
    "print type(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这样就明白了：除了r.text返回的内容外，其它几乎都是使用str格式，也就是bytes二进制码。所以我们只要转化requests相关的内容就行！\n",
    "\n",
    "实际上，requests返回的response中, 除了用`response.text`获取内容，我们还可以用`response.content`获取同样的内容，只不过是bytes格式。\n",
    "\n",
    "那就正和我们意，不用再去转化每一个地方的字符串，而只要盯紧这一个地方就足够了。\n",
    "\n",
    "### 为什么我们不能把所有字符串变量统一为unicode呢？\n",
    "提前说明，变成unicode的过程，叫`decoding`。不要记错。\n",
    "\n",
    "因为像`response.text`经常把`ISO8859`等猜不到也检测不到编码(机率很低)的字符串扔过来，如果遇到的话，是很麻烦的。\n",
    "\n",
    "`decoding`有两种方法：\n",
    "```\n",
    "unicode(b'你好‘）\n",
    "b'你好'.decode('utf-8')\n",
    "```\n",
    "\n",
    "这里因为不知道来源的编码，所以必须用`unicode()`来解码，而不能用`.decode('utf-8')`，因为显然你不能乱写解码名称，如果来源果真是（很大几率是）`ISO8859`等方式，那么错误的解码肯定会产生乱码，或者直接程序报错。切记！\n",
    "\n",
    "所以这里只能用`unicode()`解码。如下例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unicode(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里好像没问题，变成了unicode。但是！但是一旦我们需要输出字符串，那么就必须要str格式的才能输出。\n",
    "\n",
    "这时候我们怎么办呢？只能用`bytes()`再把它转成str格式，同理，因为不知道来源的编码格式，不能用`.encode('utf-8')`这个方法来转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 276-281: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-4c4a03050b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 276-281: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# 来看看\n",
    "type(bytes( unicode(r.text) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本阶段总结：一定记住，全文都统一用`str`格式字符串\n",
    "### 只要盯紧requests等相关的网络操作就好了，只要控制好外来源的字符串，统一为`str`，其它一切都好说！\n",
    "\n",
    "下面是一个从获取网络资源（含中文且被requests认为编码是ISO8850的网页）到本地操作且存储到本地文件的完整测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('http://pycoders-weekly-chinese.readthedocs.io/en/latest/issue5/unipain.html')\n",
    "\n",
    "# write a webpage to local file\n",
    "with open('test.html', 'w') as f:\n",
    "    f.write( r.content )\n",
    "\n",
    "# read from a local html file\n",
    "with open('test.html', 'r') as f:\n",
    "    ss = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 再来试一个从网上获取json并转化为JSON格式变量然后又存为文件的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,json\n",
    "\n",
    "r = requests.get('https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/25/comments')\n",
    "\n",
    "# 获取到我的github中某条issue的所有评论，形式为<JSON格式的字符串>\n",
    "comments = json.loads( r.content )\n",
    "# 取某一条评论查看内容（中文）\n",
    "cc = comments[0]['body'][0:10] # 取出的内容是'## 配置：先从配置'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'## \\u914d\\u7f6e\\uff1a\\u5148\\u4ece\\u914d\\u7f6e'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以看到是<unicode格式的字符串>\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 配置：先从配置\n"
     ]
    }
   ],
   "source": [
    "# <print大法>，即使是<unicode格式的字符串>也能直接显示出来\n",
    "print cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe9 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-0d3b2b0a9339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 那么能不能在操作中正常使用这个unicode字符串呢？显然不行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m'配'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe9 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# 那么能不能在操作中正常使用这个unicode字符串呢？显然不行\n",
    "'配' in cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-258-36bd63426932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# <JSON对象>里unicode格式的数据，和<手动声明的str格式字符串>一起操作会怎么样？\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'你好'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# <JSON对象>里unicode格式的数据，和<手动声明的str格式字符串>一起操作会怎么样？\n",
    "cc + '你好'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4f60\\u597d## \\u914d\\u7f6e\\uff1a\\u5148\\u4ece\\u914d\\u7f6e'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'你好'.decode('utf-8') + cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## \\xe9\\x85\\x8d\\xe7\\xbd\\xae\\xef\\xbc\\x9a\\xe5\\x85\\x88\\xe4\\xbb\\x8e\\xe9\\x85\\x8d\\xe7\\xbd\\xae'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看它转化为<str格式的字符串>的实质内容\n",
    "cc.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 意思是，即使字符串本身显示的是'\\xe9\\x85\\x8d` 也能直接匹配到\n",
    "'配' in cc.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 配置：\n"
     ]
    }
   ],
   "source": [
    "# <JSON对象>的某一部分数据取出来后，写入文本文档然后再读出来\n",
    "with open('test.txt', 'w') as f:\n",
    "    f.write( cc.encode('utf-8') )\n",
    "with open('test.txt', 'r') as f:\n",
    "    print f.read()[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也就是说，其实，从网络资源获取，到`json.load()`将json字符串转化为json对象的。\n",
    "\n",
    "### 将`JSON对象`的某一段内容编码后，可以正常存取文件，那么再来试试将`JSON对象`整体存到文本文件中。\n",
    "### 重点必须要在json.dumps()里把`ensure_ascii`参数选为False !否则它会将所有非ascii码用repr()强制转化为代号（而非汉字）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"body\": \"\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\"}'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing = json.dumps({\"body\": \"你好\"}, ensure_ascii=False)\n",
    "\n",
    "outgoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"body\": \"## 配置：先从配 <type 'unicode'>\n"
     ]
    }
   ],
   "source": [
    "print outgoing[0:20], type(outgoing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"body\": \"## 配置：先从配 <type 'unicode'>\n"
     ]
    }
   ],
   "source": [
    "# @网络资源到本地存储真实测试\n",
    "outgoing = json.dumps( comments, ensure_ascii=False )\n",
    "\n",
    "print outgoing[0:20], type(outgoing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"body\": \"## 配置 <type 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open('test.txt', 'w') as f:\n",
    "    f.write(outgoing.encode('utf-8'))\n",
    "with open('test.txt', 'r') as f:\n",
    "    read = f.read()\n",
    "    \n",
    "print read[0:20], type(read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 大功告成！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confidence': 0.505, 'encoding': 'utf-8', 'language': ''}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @1 chardet库的方法\n",
    "from chardet import detect\n",
    "detect(b'\\xe9\\x85\\x8d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso-8859-9\n"
     ]
    }
   ],
   "source": [
    "# @2 由BeautifulSoup制作的UnicodeDammit方法\n",
    "from bs4 import UnicodeDammit\n",
    "dammit = UnicodeDammit(\"Sacr\\xc3\\xa9 bleu!\")\n",
    "print dammit.original_encoding\n",
    "# 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Sacr\\xc3\\xa9 bleu!'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dammit.unicode_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sacré bleu!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'latin-1'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dammit = UnicodeDammit(\"Sacr\\xe9 bleu!\", [\"latin-1\", \"iso-8859-1\"])\n",
    "print(dammit.unicode_markup)\n",
    "# Sacré bleu!\n",
    "dammit.original_encoding\n",
    "# 'latin-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
