{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关于解决Python乱码问题的终极解决方案\n",
    "\n",
    "> 这里打算讨论各种常用方法\n",
    "\n",
    "简单来说，只要记住，在Python2里字符串只有两大阵营：\n",
    "\n",
    "## `unicode`和`bytes`\n",
    "\n",
    "如果`type(字符串)`显示结果是`str`，那么就是指的`bytes`二进制码。\n",
    "而其它各种我们所说的`utf-8`，`gb2312`等等也都是Unicode的不同实现方式。\n",
    "这里不要去考虑那么复杂，只要先记住这两大阵营就行。\n",
    "\n",
    "## `encoding`和`decoding`\n",
    "\n",
    "绝对要记住的：\n",
    "从`unicode`转换到`bytes`，这个叫`encoding`，编码。\n",
    "从`bytes`转换到`unicode`，这个叫`decoding`，解码。\n",
    "\n",
    "来回记住这个问题，才能进入下一步！\n",
    "\n",
    "然后来看个案例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'你好'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4f60\\u597d'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'你好'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u'你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b'你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(u'你好')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 通过上面两种格式的对比我们看到，str和unicode的各种区别。\n",
    "\n",
    "那么，既然变量里面会出现两种不同的格式，如果我们把两种格式的字符串连在一起操作会发生什么呢？\n",
    "如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni = u'你好'\n",
    "type(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byt = b'你好'\n",
    "type(byt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-b7e7514f02ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muni\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbyt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "uni + byt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 看！著名的`UnicodeDecodeError: 'ascii' codec can't decode byte`编码错误就这样出现了！\n",
    "\n",
    "以上是我们用`显性`字符串来比较两种格式字符串的区别。\n",
    "\n",
    "但是，我们经常性处理python编码问题，都不是在这种`显性`的字符串上出现的，不是从网上爬取的就是从本地文件读取的。\n",
    "意思就是网络来源文件内容庞大复杂，编码格式很难猜到是什么。\n",
    "\n",
    "> 不过如果你非要猜的话，可以自己手动测试一下`chardet`库和`UnicodeDammit`两种外来库函数来猜。\n",
    "它们猜的时候会告诉你某段字符串的`可能格式`和这个可能性的机率。\n",
    "看着很爽，但是光用`你好`两个字来实测一下就知道\n",
    "\n",
    "\n",
    "这里为了思路清晰一点，我们要拆分为两部分进行测试：本地文件和网络资源。\n",
    "\n",
    "## 本地文件编码测试\n",
    "首先在本地建立一个有中文的以`utf-8`格式保存的文本文件（实际上无论.txt还是.md等都无所谓，内容是一样的）。\n",
    "内容只有'你好'。\n",
    "\n",
    "### 然后我们来读取一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test.txt', 'r') as f:\n",
    "    ss = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 上面看到，从文件读取出来的，就是bytes二进制格式。\n",
    "那么如果要把bytes转化为unicode，就要解码，也就是decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4f60\\u597d'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这种时候实际上是最迷糊也最容易造成之后错误的，就是分不清该编码还是该解码。\n",
    "\n",
    "> 所以上面提到，必须要记住这两个区别。\n",
    "那么如果现在我搞反了怎么办？就会再次出现下面错误："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-9a2ff796dd55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "ss.encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 话说回来，我们该怎么统一他们呢？\n",
    "> 为了避免两种格式的字符串在一起乱搞，统一他们是必须的。但是以哪一种为统一的呢，unicode还是bytes?\n",
    "\n",
    "#### 下面我们来看看做常用的环境下字符串都是什么格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文中声明的变量\n",
    "type('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取本地文件\n",
    "ff = open('test.txt', 'r')\n",
    "type(ff.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'unicode'>\n",
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "# 获取网路资源\n",
    "import requests\n",
    "r = requests.get('http://pycoders-weekly-chinese.readthedocs.io/en/latest/issue5/unipain.html')\n",
    "print type(r.text)\n",
    "print type(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这样就明白了：除了r.text返回的内容外，其它几乎都是使用str格式，也就是bytes二进制码。所以我们只要转化requests相关的内容就行！\n",
    "\n",
    "实际上，requests返回的response中, 除了用`response.text`获取内容，\n",
    "我们还可以用`response.content`获取同样的内容，`.content`返回的是bytes格式。\n",
    "\n",
    "那就正和我们意，不用再去转化每一个地方的字符串，而只要盯紧这一个地方就足够了。\n",
    "\n",
    "### 为什么我们不能把所有字符串变量统一为unicode呢？\n",
    "提前说明，变成unicode的过程，叫`decoding`。不要记错。\n",
    "\n",
    "因为像`response.text`经常把`ISO8859`等猜不到也检测不到编码(机率很低)的字符串扔过来，如果遇到的话，是很麻烦的。\n",
    "\n",
    "`decoding`有两种方法：\n",
    "```\n",
    "unicode(b'你好‘）\n",
    "b'你好'.decode('utf-8')\n",
    "```\n",
    "\n",
    "这里因为不知道来源的编码，所以必须用`unicode()`来解码，而不能用`.decode('utf-8')`，因为显然你不能乱写解码名称，如果来源果真是（很大几率是）`ISO8859`等方式，那么错误的解码肯定会产生乱码，或者直接程序报错。切记！\n",
    "\n",
    "所以这里只能用`unicode()`解码。如下例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unicode(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里好像没问题，变成了unicode。但是！但是一旦我们需要输出字符串，那么就必须要str格式的才能输出。\n",
    "\n",
    "这时候我们怎么办呢？只能用`bytes()`再把它转成str格式。\n",
    "同理，因为不知道来源的编码格式，不能用`.encode('utf-8')`这个方法来转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 276-281: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-4c4a03050b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 276-281: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# 来看看\n",
    "type(bytes( unicode(r.text) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本阶段总结：一定记住，全文都统一用`str`格式字符串\n",
    "> 只要盯紧requests等相关的网络操作就好了，只要控制好外来源的字符串，统一为`str`，其它一切都好说！\n",
    "\n",
    "下面是一个从获取网络资源（含中文且被requests认为编码是ISO8850的网页）到本地操作且存储到本地文件的完整测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('http://pycoders-weekly-chinese.readthedocs.io/en/latest/issue5/unipain.html')\n",
    "\n",
    "# write a webpage to local file\n",
    "with open('test.html', 'w') as f:\n",
    "    f.write( r.content )\n",
    "\n",
    "# read from a local html file\n",
    "with open('test.html', 'r') as f:\n",
    "    ss = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 再来试一个从网上获取json并又存到本地文件的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,json\n",
    "\n",
    "r = requests.get('https://api.github.com/repos/solomonxie/\\\n",
    "solomonxie.github.io/issues/25/comments')\n",
    "\n",
    "# 获取到我的github中某条issue的所有评论，形式为<JSON格式的字符串>\n",
    "comments = json.loads( r.content )\n",
    "\n",
    "# 取某一条评论查看内容（中文）\n",
    "cc = comments[0]['body'][0:10] # 取出的内容是'## 配置：先从配置'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'## \\u914d\\u7f6e\\uff1a\\u5148\\u4ece\\u914d\\u7f6e', unicode)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc, type(cc)\n",
    "\n",
    "# 可以看到输出的是<unicode格式的字符串> 注：这时如果用print是能正常出中文的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 好，到这里先停一下！\n",
    "JSON的读取到目前为止，都是正常的：JSON Object对象给出的值都是unicode，没有被莫名转义，也没有报错误。\n",
    "> 但是，unicode格式，意味着它和str格式不兼容！\n",
    "这时，害羞的大姑娘Unicode刚出炉，你不能在这个时候让它和Str操作在一起！\n",
    "报错也往往就在这种疏于防备的时候！\n",
    "\n",
    "比如你看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ## 配置：先从配置显性声明的字符串\n",
      "2 ## 配置：先从配置显性声明的字符串\n",
      "3"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-371-41866659ac68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'显性声明的字符串'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'显性声明的字符串'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'显性声明的字符串'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "print 1, cc.encode('utf-8') + '显性声明的字符串'\n",
    "print 2, cc + '显性声明的字符串'.decode('utf-8')\n",
    "print 3, cc + '显性声明的字符串'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面打印了三条Unicode和Str的结合，\n",
    "前两条分别是以Str格式的结合，以Unicode格式的结合。\n",
    "但是第三条，把两个不同格式的字符串结合，就出错了。\n",
    "\n",
    "对不起，这里不是Javascript，变量不可以任意交合。Python对变量和编码都是极其谨慎的。\n",
    "\n",
    "所以明白了这点，我们再继续。\n",
    "\n",
    "### 上面获得了JSON Object对象，那么再来试试将`JSON对象`整体存到文本文件中。\n",
    "如果要存到本地文件，那么就必须把Object对象转换为Str格式的字符串。\n",
    "json库自带.dumps()函数可以进行转化。\n",
    "但是这里问题出现了！我们来小试一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"body\": \"\\u4f60\\u597d\"}\n"
     ]
    }
   ],
   "source": [
    "print json.dumps( {\"body\": \"你好\"} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 竟然连`print大法`都不能把`json.dumps()`返回的内容正确打印出来。经过各种测试和查看官网对于此函数的文档，发现：\n",
    "\n",
    "### 原来`json.dumps()`是默认所有非ascii码强制转化为代号（而非汉字）的，于`repr()`效果等同！\n",
    "[官方文档](https://docs.python.org/2/library/json.html#encoders-and-decoders)里有说明，`json.dumps()`里面有个`ensure_ascii`参数，默认为True。\n",
    "意思就是默认把所有非ascii字码用`\\`强制转化。所以，为了关闭这个功能，我们必须把它设为`False`.\n",
    "下面是个小测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"body\": \"\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\"}'"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "json.dumps({\"body\": \"你好\"}, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这样一来JSON在Python里的编码问题就解决了：须用`json.dumps(obj,  ensure_ascii=False)`来转化为字符串\n",
    "\n",
    "下面是完整的代码测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"body\": \"## 配置 <type 'str'>\n"
     ]
    }
   ],
   "source": [
    "# @网络资源到本地存储真实测试\n",
    "import requests,json\n",
    "\n",
    "r = requests.get('https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/25/comments')\n",
    "\n",
    "# 获取到我的github中某条issue的所有评论，形式为<JSON格式的字符串>\n",
    "comments = json.loads( r.content )\n",
    "\n",
    "outgoing = json.dumps( comments, ensure_ascii=False )\n",
    "\n",
    "with open('test.txt', 'w') as f:\n",
    "    f.write(outgoing.encode('utf-8'))\n",
    "with open('test.txt', 'r') as f:\n",
    "    read = f.read()\n",
    "    \n",
    "print read[0:20], type(read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 大功告成！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confidence': 0.505, 'encoding': 'utf-8', 'language': ''}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @1 chardet库的方法\n",
    "from chardet import detect\n",
    "detect(b'\\xe9\\x85\\x8d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso-8859-9\n"
     ]
    }
   ],
   "source": [
    "# @2 由BeautifulSoup制作的UnicodeDammit方法\n",
    "from bs4 import UnicodeDammit\n",
    "dammit = UnicodeDammit(\"Sacr\\xc3\\xa9 bleu!\")\n",
    "print dammit.original_encoding\n",
    "# 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Sacr\\xc3\\xa9 bleu!'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dammit.unicode_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sacré bleu!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'latin-1'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dammit = UnicodeDammit(\"Sacr\\xe9 bleu!\", [\"latin-1\", \"iso-8859-1\"])\n",
    "print(dammit.unicode_markup)\n",
    "# Sacré bleu!\n",
    "dammit.original_encoding\n",
    "# 'latin-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
